# -*- coding: utf-8 -*-
"""E_Video_Summarizer.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c3_WabyDobWktdg_UXdFZv-WW-SxUytg
"""

# Cell 1: Install Dependencies and FFMPEG

print("Installing FFMPEG...")
# FFMPEG is crucial for audio extraction
!apt-get install -y ffmpeg

print("Installing Python Libraries...")
# Core ML/AI Libraries
!pip install git+https://github.com/openai/whisper.git
!pip install transformers accelerate
!pip install torch torchvision torchaudio
# Video Processing and Utilities
!pip install moviepy
!pip install ultralytics
!pip install opencv-python
!pip install easyocr
!pip install pytube --upgrade # CRITICAL FIX for YouTube download errors
!pip install sentencepiece
# Frontend and Public Access
!pip install streamlit
!pip install pyngrok
!pip install watchdog

# Commented out IPython magic to ensure Python compatibility.
# # Cell 2: Create youtube_downloader.py
# 
# %%writefile youtube_downloader.py
# # youtube_downloader.py
# 
# from pytube import YouTube
# import os
# 
# def download_youtube_video(url: str, output_path: str = "youtube_video_download.mp4") -> str:
#     try:
#         if os.path.exists(output_path):
#             os.remove(output_path)
# 
#         yt = YouTube(url)
#         yt.bypass_age_gate()
# 
#         stream = yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first()
# 
#         if stream is None:
#             stream = yt.streams.get_highest_resolution()
# 
#         if stream is None:
#              raise Exception("Could not find any suitable MP4 stream for download. The video may be region-locked or private.")
# 
#         print(f"Downloading: {yt.title}")
#         stream.download(filename=output_path)
#         print(f"Download complete: {output_path}")
#         return output_path
# 
#     except Exception as e:
#         print(f"An error occurred during YouTube download: {e}")
#         raise

# Commented out IPython magic to ensure Python compatibility.
# # Cell 3: Create transcriber.py
# 
# %%writefile transcriber.py
# # transcriber.py
# 
# import subprocess
# import whisper
# import os
# 
# def extract_audio(video_path: str, audio_path: str = "temp_audio.wav") -> str:
#     # This must be outside the `try/except` for FFmpeg to run
#     if os.path.exists(audio_path):
#         os.remove(audio_path)
#     command = [
#         "ffmpeg", "-i", video_path, "-q:a", "0", "-map", "a", audio_path, "-y"
#     ]
#     # Uses subprocess to run the command line tool FFmpeg
#     subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, check=True)
#     return audio_path
# 
# def transcribe_audio(audio_path: str, model_size: str = "base", device: str = "cpu") -> tuple[str, str]:
#     """Transcribes and returns the transcript and detected language code."""
# 
#     print(f"Loading Whisper model: {model_size} on device: {device}...")
#     model = whisper.load_model(model_size, device=device)
# 
#     print("Starting transcription...")
#     result = model.transcribe(audio_path)
# 
#     detected_lang_code = result.get('language', 'en')
# 
#     print(f"\n*******************")
#     print(f"DETECTED LANGUAGE: {detected_lang_code.upper()}")
#     print(f"*******************\n")
# 
#     if os.path.exists(audio_path):
#         os.remove(audio_path)
# 
#     return result['text'], detected_lang_code

# Commented out IPython magic to ensure Python compatibility.
# # Cell 4: Create summarizer.py
# 
# %%writefile summarizer.py
# # summarizer.py (Using BART for stable, clean summarization)
# 
# from transformers import pipeline
# import torch
# 
# # Use the established BART large CNN model
# BART_MODEL_NAME = "facebook/bart-large-cnn"
# 
# def summarize_text(
#         text: str,
#         model_name:str = BART_MODEL_NAME,
#         max_length: int = 200,
#         min_length: int = 50,
#         language_code: str = "en",
#         device: str = "cpu"
# ) -> str:
# 
#     device_int = 0 if device == "cuda" and torch.cuda.is_available() else -1
# 
#     print(f"Loading Summarization Model ({model_name}) on pipeline device: {device_int}...")
# 
#     summarizer = pipeline(
#         "summarization",
#         model=model_name,
#         tokenizer=model_name,
#         device=device_int
#     )
# 
#     # BART takes the text directly for summarization
#     summary = summarizer(
#         text,
#         max_length=max_length,
#         min_length=min_length,
#         do_sample=False
#     )
# 
#     return summary[0]['summary_text']

# Commented out IPython magic to ensure Python compatibility.
# # Cell 5: Create vision_processor.py
# 
# %%writefile vision_processor.py
# # vision_processor.py
# 
# import cv2
# from ultralytics import YOLO
# import easyocr
# import numpy as np
# 
# def extract_vision_data(video_path: str, frames_to_sample: int = 30, device: str = "cpu") -> str:
#     vision_data = []
# 
#     object_model = YOLO('yolov8n.pt')
#     use_gpu_ocr = device == 'cuda'
#     reader = easyocr.Reader(['en'], gpu=use_gpu_ocr)
# 
#     cap = cv2.VideoCapture(video_path)
#     if not cap.isOpened():
#         return "No visual data could be extracted."
# 
#     frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
#     frames_to_sample = max(1, frames_to_sample)
# 
#     if frame_count <= frames_to_sample:
#           sample_indices = list(range(frame_count))
#     else:
#         sample_indices = np.round(np.linspace(0, frame_count - 1, frames_to_sample)).astype(int)
# 
#     print(f"Total frames: {frame_count}, Sampling {len(sample_indices)} frames...")
# 
#     for i in sample_indices:
#         cap.set(cv2.CAP_PROP_POS_FRAMES, i)
#         ret, frame = cap.read()
# 
#         if not ret:
#             continue
# 
#         # 1. Object Detection (YOLOv8)
#         results = object_model(frame, device=device, verbose=False)
#         detected_objects = []
#         for r in results:
#             for c in r.boxes.cls:
#                 class_name = object_model.names[int(c)]
#                 detected_objects.append(class_name)
# 
#         unique_objects = sorted(list(set(detected_objects)))
#         if unique_objects:
#             object_description = f"Objects detected: {', '.join(unique_objects)}."
#             vision_data.append(object_description)
# 
#         # 2. Text Detection (EasyOCR)
#         ocr_results = reader.readtext(frame, detail=0)
# 
#         if ocr_results:
#             filtered_text = [
#                 t.strip() for t in ocr_results
#                 if len(t.strip()) > 3 and not any(word in t.lower() for word in ['sponsored', 'shop', 'buy', 'link', 'video', 'ad', 'skip'])
#             ]
#             if filtered_text:
#                 text_description = f"Text visible on screen: \"{' '.join(filtered_text)}\"."
#                 vision_data.append(text_description)
# 
# 
#     cap.release()
#     final_vision_data = " ".join(vision_data)
# 
#     if not final_vision_data:
#         final_vision_data = "No significant objects or text were detected on screen."
# 
#     return final_vision_data

# Commented out IPython magic to ensure Python compatibility.
# # Cell 6: Create utils.py
# 
# %%writefile utils.py
# # utils.py
# 
# def chunk_text(text: str, chunk_size: int = 2000, overlap: int = 200) -> list:
#     chunks = []
#     start = 0
#     text_length = len(text)
# 
#     while start < text_length:
#         end = min(start + chunk_size, text_length)
#         chunk = text[start:end]
#         chunks.append(chunk)
# 
#         start += chunk_size - overlap
#         if start < 0:
#             start = 0
# 
#     return chunks
# 
# def chunked_summarizer(text: str, summarize_func, max_chunk_size: int = 2000) -> str:
#     print(f"Text too large for single summary. Chunking text with size {max_chunk_size}...")
#     text_chunks = chunk_text(text, chunk_size=max_chunk_size, overlap=200)
# 
#     partial_summaries = [summarize_func(chunk) for chunk in text_chunks]
# 
#     combined_summary_input = " ".join(partial_summaries)
#     print(f"Partial summaries combined. Total length for final summary: {len(combined_summary_input)} characters.")
# 
#     final_summary = summarize_func(combined_summary_input)
#     return final_summary

# Commented out IPython magic to ensure Python compatibility.
# # Cell 7: Create main.py
# 
# %%writefile main.py
# # main.py
# 
# import os
# from transcriber import extract_audio, transcribe_audio
# from summarizer import summarize_text, BART_MODEL_NAME
# from utils import chunked_summarizer
# from vision_processor import extract_vision_data
# 
# def video_to_summary(
#         video_path: str,
#         model_size: str = "base",
#         summarizer_model_name: str = BART_MODEL_NAME, # Uses BART
#         use_chunking: bool = False,
#         device: str = "cpu"
# ) -> str:
# 
#     audio_path = "temp_audio.wav"
# 
#     # 1. Extract Audio & Transcribe
#     extract_audio(video_path, audio_path)
#     transcript, detected_lang_code = transcribe_audio(audio_path, model_size=model_size, device=device)
# 
#     # 2. Extract Visual Data
#     vision_data = extract_vision_data(video_path, frames_to_sample=30, device=device)
# 
#     # 3. Combine Transcript and Vision Data
#     combined_text = f"SPEECH TRANSCRIPT: {transcript}\n\nVISUAL DATA: {vision_data}"
# 
#     print(f"\n--- Combined Input Text ---\n{combined_text[:500]}...\n---------------------------\n")
# 
#     def perform_summary(txt):
#         return summarize_text(
#             txt,
#             model_name=summarizer_model_name,
#             language_code=detected_lang_code,
#             device=device
#         )
# 
#     # 4. Summarize Combined Text
#     if use_chunking:
#         final_summary = chunked_summarizer(
#             text=combined_text,
#             summarize_func=perform_summary
#         )
#     else:
#         final_summary = perform_summary(combined_text)
# 
#     if os.path.exists(video_path):
#           os.remove(video_path)
# 
#     return final_summary

# Commented out IPython magic to ensure Python compatibility.
# # Cell 8: Create app.py
# 
# %%writefile app.py
# # app.py (FINAL UPDATED VERSION)
# 
# import streamlit as st
# import os
# import torch
# from main import video_to_summary
# from youtube_downloader import download_youtube_video
# 
# def main():
#     st.set_page_config(page_title="Multi-Modal Video Summarizer AI", layout="wide")
#     st.title("ðŸŽ¬ Multi-Modal Video Summarizer AI")
#     st.markdown("---")
# 
#     # --- Device Configuration ---
#     device = "cuda" if torch.cuda.is_available() else "cpu"
#     if device == "cuda":
#         st.sidebar.success(f"âš¡ GPU Detected in Colab! Using **{torch.cuda.get_device_name(0)}** for fast processing.")
#     else:
#         st.sidebar.error("âš ï¸ No GPU Detected. Processing will run on CPU and may be slow.")
# 
#     # --- Video Input Options ---
#     col1, col2 = st.columns(2)
#     video_path_to_process = None
# 
#     with col1:
#         st.subheader("1. Upload a Video File ðŸ“")
#         uploaded_file = st.file_uploader("Drag and drop your video here (mp4, mov, avi, mkv)", type=["mp4", "mov", "avi", "mkv"])
# 
#         if uploaded_file is not None:
#             temp_path = "uploaded_video.mp4"
#             with open(temp_path, "wb") as f:
#                 f.write(uploaded_file.read())
# 
#             # --- CRITICAL FIX: Verify saved file existence and size ---
#             if os.path.exists(temp_path) and os.path.getsize(temp_path) > 0:
#                 video_path_to_process = temp_path
#                 st.success(f"File uploaded successfully! Size: {os.path.getsize(temp_path) / (1024*1024):.2f} MB")
#             else:
#                 st.error("Error: Uploaded file was saved but appears to be empty or corrupted.")
#                 video_path_to_process = None
# 
#     with col2:
#         st.subheader("2. Enter a YouTube URL ðŸ”—")
#         youtube_url = st.text_input("Paste the YouTube video URL:")
# 
#         if youtube_url and not uploaded_file:
#             try:
#                 temp_path = "youtube_video_download.mp4"
#                 with st.spinner("Downloading YouTube video..."):
#                     downloaded_path = download_youtube_video(youtube_url, temp_path)
# 
#                 # --- CRITICAL FIX: Verify downloaded file existence and size ---
#                 if os.path.exists(downloaded_path) and os.path.getsize(downloaded_path) > 0:
#                     video_path_to_process = downloaded_path
#                     st.success("YouTube video downloaded!")
#                 else:
#                     st.error("Error: Download failed or resulted in an empty file. Check the URL validity.")
#                     video_path_to_process = None
# 
#             except Exception as e:
#                 st.error(f"Error downloading YouTube video. Detailed error: {e}")
#                 video_path_to_process = None
# 
#     st.markdown("---")
# 
#     # --- Processing Logic ---
#     if video_path_to_process is not None:
# 
#         st.subheader("Video to Summarize")
#         st.video(video_path_to_process)
#         st.markdown("---")
# 
#         if st.button("Start Multi-Modal Summarization", type="primary"):
# 
#             with st.spinner(f"Transcribing, detecting objects/text, and generating summary on **{device.upper()}**. This may take a few minutes..."):
#                 try:
#                     summary_result = video_to_summary(
#                         video_path=video_path_to_process,
#                         model_size="base",
#                         use_chunking=True,
#                         device=device
#                     )
# 
#                     st.subheader("Final Multi-Modal Summary")
#                     st.info(summary_result)
# 
#                 except Exception as e:
#                     st.error(f"An error occurred during processing: {e}")
# 
#                 finally:
#                     # Clean up
#                     if os.path.exists(video_path_to_process):
#                         os.remove(video_path_to_process)
#                     if os.path.exists("temp_audio.wav"):
#                         os.remove("temp_audio.wav")
# 
# 
# if __name__ == "__main__":
#     main()

# 1. Force Uninstall the currently broken version
print("Attempting to fix pytube 403 error by forcing re-installation...")
!pip uninstall pytube -y

# 2. Install the latest unreleased, patched version directly from GitHub
# This is the most reliable way to bypass the 403 Forbidden error.
!pip install git+https://github.com/pytube/pytube.git

# 3. Verify the installation (using the correct method for the GitHub version)
import pkg_resources
pytube_version = pkg_resources.get_distribution("pytube").version
print(f"Pytube version after fix (from GitHub): {pytube_version}")

# 4. Quick check for the critical file to ensure it's still present
import os
if os.path.exists("youtube_downloader.py"):
    print("\nyoutube_downloader.py is present. Ready to proceed.")
else:
    print("\nFATAL ERROR: youtube_downloader.py is missing. Please re-run Cell 2.")

# Cell 9: Launch Streamlit with ngrok

from pyngrok import ngrok
import subprocess

# 1. SET YOUR NGROK AUTH TOKEN HERE
# REPLACE THE TEXT BELOW WITH YOUR ACTUAL NGROK TOKEN!
NGROK_AUTH_TOKEN = "34WKK0Sj6w2fngjqpD5koRU4DxL_5YMggd3qLXR2482u3Epkq"
ngrok.set_auth_token(NGROK_AUTH_TOKEN)

# 2. Start ngrok tunnel for port 8501
public_url = ngrok.connect(8501)
print(f"ðŸš€ Streamlit App is running! Click the URL below:")
print(f"ðŸ”— {public_url}")

# 3. Run the Streamlit app in the background
subprocess.Popen(['streamlit', 'run', 'app.py', '--server.port', '8501'])

# This cell must remain running to keep the app alive!
print("\n* NOTE: This cell must remain running to keep the app alive. DO NOT STOP IT. *")